<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Pengdeng Li's Homepage</title>
</head>

<body>

<div id="layout-content">
<!-- <div id="toptitle">
<h1>Pengdeng Li</h1>
</div> -->
<table class="imgtable"><tr><td>
<a href="https://ipadli.github.io/"><img src="picture/view.jpg" alt="alt text" /></a>&nbsp;</td>
<td align="middle"><p>&nbsp;&nbsp;<h1>Pengdeng Li</h1><br/>
    <b>Associate Professor</b><br/>
    <a href="https://wyy.gzhu.edu.cn/">School of Cybersecurity (Huangpu)</a> <br/>
    <a href="https://www.gzhu.edu.cn/">Guangzhou University, China</a> <br/><br/>
    <a href="mailto:pengdengli01@gmail">[Gmail]</a>
    <a href="https://scholar.google.com/citations?user=HY6ghxoAAAAJ&hl=en">[Google Scholar]</a>
<!--    <a href="pdf/cv_pengdeng.pdf">[Curriculum Vitae]</a><br/>-->
</td></tr></table>

    <br/>
    <br/>
    <br/>

<h2>Research Interests</h2>
  Cybersecurity, Multi-Agent Reinforcement Learning/Algorithmic Game Theory, Optimization
<!-- (Multi-Agent) (Reinforcement) Learning, and (Distributed) Foundation Models/Agents. -->

<!--<h2>Education</h2>-->
<!--    <ul>-->
<!--    <li><p><a href="https://www.cqu.edu.cn/">Chongqing University, China</a> <br/>-->
<!--    Ph.D, School of Big Data & Soft Engineering <br/>-->
<!--    Supervisor: Prof. <a href="http://www.cse.cqu.edu.cn/info/2095/3484.htm">Xiaofan Yang</a> </p>-->
<!--    </li>-->
<!--    </ul>-->

<!--    <ul>-->
<!--    <li><p><a href="https://www.cqu.edu.cn/">Chongqing University, China</a> <br/>-->
<!--    Bachelor of Science, School of Big Data & Soft Engineering </p>-->
<!--    </li>-->
<!--    </ul>-->
  
<!--<h2>Preprints</h2>-->


<h2>Selected Publications</h2>
(<sup>*</sup> indicates equal contribution)<br/>

    <ul>
    <li><p><a href="https://arxiv.org/abs/2405.11746">
        Configurable Mirror Descent: Towards a Unification of Decision Making</a> <br />
        <b>Pengdeng Li</b>, Shuxin Li<sup>*</sup>, Chang Yang<sup>*</sup>, Xinrun Wang, Shuyue Hu, Xiao Huang, Hau Chan, Bo An <br />
        <i>Proceedings of the 41st International Conference on Machine Learning (<b>ICML'24</b>), 2024 </i></p>
    </li>
    </ul>

    <ul>
    <li><p><a href="https://arxiv.org/abs/2404.11144">
        Self-adaptive PSRO: Towards an Automatic Population-based Game Solver</a> <br />
        <b>Pengdeng Li</b>, Shuxin Li, Chang Yang, Xinrun Wang, Xiao Huang, Hau Chan, Bo An <br />
        <i>Proceedings of the 33rd International Joint Conference on Artificial Intelligence (<b>IJCAI'24</b>), 2024</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/29696">
        Transition-informed Reinforcement Learning for Large-Scale Stackelberg Mean-Field Games</a> <br/>
        <b>Pengdeng Li</b>, Runsheng Yu, Xinrun Wang, Bo An <br />
        <i>Proceedings of the 38th AAAI Conference on Artificial Intelligence (<b>AAAI'24</b>), 2024</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a href="https://arxiv.org/abs/2404.12626">
        Grasper: A Generalist Pursuer for Pursuit-Evasion Problems</a> <br/>
        <b>Pengdeng Li</b><sup>*</sup>, Shuxin Li<sup>*</sup>, Xinrun Wang, Jakub Cerny, Youzhi Zhang, Stephen McAleer, Hau Chan, Bo An <br />
        <i>Proceeding of the 23rd International Conference on Autonomous Agents and Multi-Agent Systems (<b>AAMAS'24</b>), 2024</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a href="https://arxiv.org/abs/2405.03518">
        Reinforcement Nash Equilibrium Solver</a> <br/>
        Xinrun Wang, Chang Yang<sup>*</sup>, Shuxin Li<sup>*</sup>, <b>Pengdeng Li</b>, Xiao Huang, Hau Chan, Bo An <br />
        <i>Proceedings of the 33rd International Joint Conference on Artificial Intelligence (<b>IJCAI'24</b>), 2024</i><br />
        Previous version appears as <i>Proceeding of the 23rd International Conference on Autonomous Agents and Multi-Agent Systems (<b>AAMAS'24</b>) (Extended Abstract), 2024</i><br /></p>
    </li>
    </ul>
  
    <ul>
    <li><p><a href="https://openreview.net/forum?id=fB4V-2QvCEm">
        Population-size-Aware Policy Optimization for Mean-Field Games</a> <br/>
        <b>Pengdeng Li</b>, Xinrun Wang, Shuxin Li, Hau Chan, Bo An<br />
        <i>The 11th International Conference on Learning Representations (<b>ICLR'23</b>), 2023</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a>
        Developing cost-effective rumor-refuting strategy through game-theoretic approach</a> <br/>
        Da-Wen Huang, Lu-Xing Yang, <b>Pengdeng Li</b>, Xiaofan Yang, Yuan Yan Tang <br/>
        <i>IEEE Systems Journal, 2020</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a>
        Simultaneous benefit maximization of conflicting opinions: Modeling and analysis</a> <br/>
        Lu-Xing Yang, <b>Pengdeng Li</b>, Xiaofan Yang, Yong Xiang, Yuan Yan Tang <br/>
        <i>IEEE Systems Journal, 2020</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a>
        Effective quarantine and recovery scheme against advanced persistent threat</a> <br/>
        Lu-Xing Yang, <b>Pengdeng Li</b>, Xiaofan Yang, Yong Xiang, Frank Jiang, Wanlei Zhou <br/>
        <i>IEEE Transactions on Systems, Man, and Cybernetics: Systems, 2019</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a>
        A discount strategy in word-of-mouth marketing</a> <br/>
        Tianrui Zhang, <b>Pengdeng Li</b>, Lu-Xing Yang, Xiaofan Yang, Yuan Yan Tang, Yingbo Wu <br/>
        <i>Communications in Nonlinear Science and Numerical Simulation, 2019</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a>
        Effective repair strategy against advanced persistent threat: A differential game approach</a> <br/>
        Lu-Xing Yang, <b>Pengdeng Li</b>, Yushu Zhang, Xiaofan Yang, Yong Xiang, Wanlei Zhou <br/>
        <i>IEEE Transactions on Information Forensics and Security (TIFS), 2018</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a>
        Discount pricing in word-of-mouth marketing: An optimal control approach</a> <br/>
        <b>Pengdeng Li</b>, Xiaofan Yang, Yingbo Wu, Weiyi He, Pengpeng Zhao <br/>
        <i>Physica A: Statistical Mechanics and its Applications, 2018</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a>
        A risk management approach to defending against the advanced persistent threat</a> <br/>
        Lu-Xing Yang, <b>Pengdeng Li</b>, Xiaofan Yang, Yuan Yan Tang <br/>
        <i>IEEE Transactions on Dependable and Secure Computing (TDSC), 2018</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a>
        The modeling and analysis of the word-of-mouth marketing</a> <br/>
        <b>Pengdeng Li</b>, Xiaofan Yang, Lu-Xing Yang, Qingyu Xiong, Yingbo Wu, Yuan Yan Tang <br/>
        <i>Physica A: Statistical Mechanics and its Applications, 2018</i></p>
    </li>
    </ul>

    <ul>
    <li><p><a>
        On the competition of two conflicting messages</a> <br/>
        Lu-Xing Yang, <b>Pengdeng Li</b>, Xiaofan Yang, Yingbo Wu, Yuan Yan Tang <br/>
        <i>Nonlinear Dynamics, 2018</i></p>
    </li>
    </ul>
  

<!-- <h2>Speculations</h2> -->
<!--    <ul>-->
<!--    <li><p>-->
<!--        The nature of reinforcement learning (RL) is contrastive learning.-->
<!--    </p>-->
<!--    </li>-->
<!--    </ul>-->

<!--     <ul>
    <li><p>
        All the methods improving over a base foundation model, i.e., prompt engineering, e.g., CoT, self-reflection, and alignment, should be addressed by  <b>a universal method</b>, maybe search.
    </p>
    </li>
    </ul>

    <ul>
    <li><p>
        All <b>decision-making</b> scenarios, including single-agent, cooperative multi-agent, competitive multi-agent, i.e., game theory,
        and mixed cooperative and competitive scenarios, will be mastered through <b>one algorithm</b>, <b>one model</b>, and even <b>one set of parameters of the model</b>.
    </p>
    </li>
    </ul> -->

<!--    <ul>-->
<!--    <li><p>-->
<!--        The <b>alignment</b> of foundation models will be <b>role-based self-alignment in unsupervised pretext tasks</b>, such as generation/discrimination in generative adversarial networks (GANs),-->
<!--        masking/reconstruction in mask autoencoders (MAEs), and noising/denoising in diffusion models.-->
<!--    </p>-->
<!--    </li>-->
<!--    </ul>-->

<!--     <ul>
    <li><p>
        The <b>Artificial General Intelligence (AGI)</b> will ultimately be i) self-improving, i.e., searching with regularly retraining, on decisions and alignment through interacting with the (virtually) embodied environments, e.g., video games, and
        ii) distributed intelligently across massive open-sourced domain-specific models.
    </p>
    </li>
    </ul> -->




<!-- 
<div id="footer">
<div id="footer-text"> -->
<!-- <br>Page generated 2021-09-18, by <a href="https://xuaikun.github.io/">Aikun Xu</a>. -->
<!-- </div>
</div> -->
</div>
</body>
</html>
